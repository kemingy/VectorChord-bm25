CREATE TYPE bm25vector (
    INPUT = _bm25catalog_bm25vector_in,
    OUTPUT = _bm25catalog_bm25vector_out,
    RECEIVE = _bm25catalog_bm25vector_recv,
    SEND = _bm25catalog_bm25vector_send,
    STORAGE = EXTERNAL,
    INTERNALLENGTH = VARIABLE,
    ALIGNMENT = double
);

CREATE TYPE bm25query AS (
    index_oid regclass,
    query_vector bm25vector
);

CREATE FUNCTION to_bm25query(index_oid regclass, query_str text) RETURNS bm25query
    IMMUTABLE STRICT PARALLEL SAFE LANGUAGE sql AS $$
        SELECT index_oid, tokenize(query_str);
    $$;

CREATE ACCESS METHOD bm25 TYPE INDEX HANDLER _bm25_amhandler;
COMMENT ON ACCESS METHOD bm25 IS 'vchord bm25 index access method';

CREATE OPERATOR pg_catalog.<&> (
    PROCEDURE = search_bm25query,
    LEFTARG = bm25vector,
    RIGHTARG = bm25query
);

CREATE OPERATOR FAMILY bm25_ops USING bm25;

CREATE OPERATOR CLASS bm25_ops FOR TYPE bm25vector USING bm25 FAMILY bm25_ops AS
    OPERATOR 1 pg_catalog.<&>(bm25vector, bm25query) FOR ORDER BY float_ops;

CREATE OR REPLACE FUNCTION tokenize_trigger()
RETURNS TRIGGER AS $$
DECLARE
    source_column TEXT := TG_ARGV[0];
    target_column TEXT := TG_ARGV[1];
    token_table TEXT := TG_ARGV[2];
    schema_name TEXT := 'bm25_catalog';
    result bm25vector;
BEGIN
    IF NOT EXISTS (
        SELECT 1
        FROM information_schema.tables
        WHERE table_schema = schema_name AND table_name = token_table
    ) THEN
        EXECUTE format('CREATE TABLE %I.%I (id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, token TEXT UNIQUE)', schema_name, token_table);
    END IF;

    EXECUTE format('select incremental_tokenize($1.%I, ''%I'')', source_column, token_table) INTO result USING NEW;
    EXECUTE format('UPDATE %I SET %I = %L WHERE id = $1.id', TG_TABLE_NAME, target_column, result) USING NEW;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION bm25_query_tokenize(index_oid regclass, query text, token_table text) RETURNS bm25query
    IMMUTABLE STRICT PARALLEL SAFE LANGUAGE sql AS $$
        SELECT index_oid, query_tokenize(query, token_table);
    $$;
